Epoch 15
batch_size 16
data_size 100.000
learning rate = 0.001

Epoch 1/15
4688/4688 [==============================] - 35s 7ms/step - loss: 0.1308
Epoch 2/15
4688/4688 [==============================] - 35s 7ms/step - loss: 0.0628
Epoch 3/15
4688/4688 [==============================] - 35s 7ms/step - loss: 0.0481
Epoch 4/15
4688/4688 [==============================] - 35s 7ms/step - loss: 0.0395
Epoch 5/15
4688/4688 [==============================] - 35s 7ms/step - loss: 0.0333
Epoch 6/15
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0288
Epoch 7/15
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0252
Epoch 8/15
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0223
Epoch 9/15
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0200
Epoch 10/15
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0181
Epoch 11/15
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0165
Epoch 12/15
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0150
Epoch 13/15
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0139
Epoch 14/15
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0129
Epoch 15/15
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0120
--- train time: 8 minutes ---
history:
{'loss': [0.13079147040843964, 0.06275944411754608, 0.04810412600636482, 0.0395306795835495, 0.033328451216220856, 0.028759023174643517, 0.025216640904545784, 0.022317249327898026, 0.020037006586790085, 0.018103979527950287, 0.016480669379234314, 0.015036340802907944, 0.013903488405048847, 0.012879186309874058, 0.011963521130383015]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0742
Loss: 0.07418553531169891
Acc whole board: 0.26
Acc single cell: 0.98
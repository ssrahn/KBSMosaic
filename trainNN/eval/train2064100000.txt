Epoch 20
batch_size 64
data_size 100.000
learning rate = 0.001

Epoch 1/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.1752
Epoch 2/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0739
Epoch 3/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0570
Epoch 4/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0476
Epoch 5/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0410
Epoch 6/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0357
Epoch 7/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0313
Epoch 8/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0278
Epoch 9/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0247
Epoch 10/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0221
Epoch 11/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0200
Epoch 12/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0182
Epoch 13/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0166
Epoch 14/20
1172/1172 [==============================] - 18s 15ms/step - loss: 0.0154
Epoch 15/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0141
Epoch 16/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0132
Epoch 17/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0123
Epoch 18/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0116
Epoch 19/20
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0108
Epoch 20/20
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0103
--- train time: 5 minutes ---
history:
{'loss': [0.17524723708629608, 0.07391366362571716, 0.05698467418551445, 0.04762250930070877, 0.040991853922605515, 0.035687025636434555, 0.03129703924059868, 0.027776507660746574, 0.02473549358546734, 0.02208705060184002, 0.020013410598039627, 0.018190134316682816, 0.016584405675530434, 0.015367252752184868, 0.01414431445300579, 0.013198642060160637, 0.012252316810190678, 0.011557500809431076, 0.010834258049726486, 0.010299952700734138]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.1755
Loss: 0.1755070835351944
Acc whole board: 0.08
Acc single cell: 0.97
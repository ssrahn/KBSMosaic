Epoch 15
batch_size 32
data_size 100.000
learning rate = 0.001

Epoch 1/15
2344/2344 [==============================] - 23s 9ms/step - loss: 0.1459
Epoch 2/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0674
Epoch 3/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0516
Epoch 4/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0425
Epoch 5/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0360
Epoch 6/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0309
Epoch 7/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0270
Epoch 8/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0237
Epoch 9/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0212
Epoch 10/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0191
Epoch 11/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0174
Epoch 12/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0158
Epoch 13/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0146
Epoch 14/15
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0135
Epoch 15/15
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0126
--- train time: 5 minutes ---
history:
{'loss': [0.14594073593616486, 0.06738835573196411, 0.05164848268032074, 0.042543403804302216, 0.0359705351293087, 0.030936289578676224, 0.02702421508729458, 0.02373935654759407, 0.021230271086096764, 0.01907542534172535, 0.017422497272491455, 0.015840334817767143, 0.01458550151437521, 0.013518722727894783, 0.01261802576482296]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0912
Loss: 0.0911688506603241
Acc whole board: 0.19
Acc single cell: 0.98
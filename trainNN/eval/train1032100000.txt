Epoch 10
batch_size 32
data_size 100.000
learning rate = 0.001

Epoch 1/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.1447
Epoch 2/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0668
Epoch 3/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0517
Epoch 4/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0425
Epoch 5/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0358
Epoch 6/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0309
Epoch 7/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0268
Epoch 8/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0236
Epoch 9/10
2344/2344 [==============================] - 21s 9ms/step - loss: 0.0211
Epoch 10/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0189
--- train time: 3 minutes ---
history:
{'loss': [0.14470045268535614, 0.06675982475280762, 0.0517316535115242, 0.04254399240016937, 0.03584878519177437, 0.030878495424985886, 0.026835018768906593, 0.02364998124539852, 0.021123716607689857, 0.018915487453341484]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0658
Loss: 0.0657874047756195
Acc whole board: 0.27
Acc single cell: 0.98


=================================================================

learning rate = 0.0001

Epoch 1/10
2344/2344 [==============================] - 23s 10ms/step - loss: 0.2943
Epoch 2/10
2344/2344 [==============================] - 22s 10ms/step - loss: 0.1228
Epoch 3/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0965
Epoch 4/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0820
Epoch 5/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0720
Epoch 6/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0646
Epoch 7/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0586
Epoch 8/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0539
Epoch 9/10
2344/2344 [==============================] - 22s 10ms/step - loss: 0.0498
Epoch 10/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0463
--- train time: 3 minutes ---
history:
{'loss': [0.29425013065338135, 0.12278717756271362, 0.09653857350349426, 0.0820365622639656, 0.07201198488473892, 0.06461668014526367, 0.05864293500781059, 0.05389989912509918, 0.0498230904340744, 0.04626515507698059]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0664
Loss: 0.06644708663225174
Acc whole board: 0.19
Acc single cell: 0.97


=================================================================

learning rate = 0.01

Epoch 1/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.1694
Epoch 2/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0827
Epoch 3/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0718
Epoch 4/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0661
Epoch 5/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0619
Epoch 6/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0589
Epoch 7/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0567
Epoch 8/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0547
Epoch 9/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0531
Epoch 10/10
2344/2344 [==============================] - 22s 9ms/step - loss: 0.0515
--- train time: 3 minutes ---
history:
{'loss': [0.16943040490150452, 0.08265137672424316, 0.07183200865983963, 0.06610502302646637, 0.06186102330684662, 0.058873653411865234, 0.05665387958288193, 0.05469249188899994, 0.053062308579683304, 0.05153713747859001]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0603
Loss: 0.06028899922966957
Acc whole board: 0.21
Acc single cell: 0.98
Epoch 10
batch_size 64
data_size 100.000
learning rate = 0.001

Epoch 1/10
1172/1172 [==============================] - 17s 14ms/step - loss: 0.1745
Epoch 2/10
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0736
Epoch 3/10
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0573
Epoch 4/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0480
Epoch 5/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0413
Epoch 6/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0361
Epoch 7/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0318
Epoch 8/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0281
Epoch 9/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0251
Epoch 10/10
1172/1172 [==============================] - 16s 14ms/step - loss: 0.0226
--- train time: 2 minutes ---
history:
{'loss': [0.174494206905365, 0.07363644242286682, 0.05726703256368637, 0.048018164932727814, 0.041296157985925674, 0.036075200885534286, 0.03184039145708084, 0.028124483302235603, 0.025085410103201866, 0.02260465733706951]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0614
Loss: 0.061436474323272705
Acc whole board: 0.27
Acc single cell: 0.98
Epoch 15
batch_size 64
data_size 100.000
learning rate = 0.001

Epoch 1/15
1172/1172 [==============================] - 18s 15ms/step - loss: 0.1769
Epoch 2/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0736
Epoch 3/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0566
Epoch 4/15
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0472
Epoch 5/15
1172/1172 [==============================] - 17s 14ms/step - loss: 0.0407
Epoch 6/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0356
Epoch 7/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0312
Epoch 8/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0277
Epoch 9/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0248
Epoch 10/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0221
Epoch 11/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0200
Epoch 12/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0182
Epoch 13/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0169
Epoch 14/15
1172/1172 [==============================] - 18s 15ms/step - loss: 0.0155
Epoch 15/15
1172/1172 [==============================] - 17s 15ms/step - loss: 0.0143
--- train time: 4 minutes ---
history:
{'loss': [0.1769428551197052, 0.07359842956066132, 0.056561022996902466, 0.04722543805837631, 0.04066373035311699, 0.03557687997817993, 0.031213417649269104, 0.027672044932842255, 0.02479671500623226, 0.022136013954877853, 0.020019421353936195, 0.01821579597890377, 0.016899464651942253, 0.01553129032254219, 0.014294988475739956]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0813
Loss: 0.0812942385673523
Acc whole board: 0.26
Acc single cell: 0.98
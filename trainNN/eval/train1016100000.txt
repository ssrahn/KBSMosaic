Epoch 10
batch_size 16
data_size 100.000
learning rate = 0.001

Epoch 1/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.1286
Epoch 2/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0634
Epoch 3/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0490
Epoch 4/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0402
Epoch 5/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0340
Epoch 6/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0293
Epoch 7/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0256
Epoch 8/10
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0227
Epoch 9/10
4688/4688 [==============================] - 33s 7ms/step - loss: 0.0204
Epoch 10/10
4688/4688 [==============================] - 34s 7ms/step - loss: 0.0183
--- train time: 5 minutes ---
history:
{'loss': [0.1286332756280899, 0.06338740885257721, 0.04900559037923813, 0.04022962972521782, 0.03396160155534744, 0.029330885037779808, 0.025563394650816917, 0.0227437112480402, 0.02041579596698284, 0.018348999321460724]}

Summary:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 9, 9, 64)          640       
                                                                 
 batch_normalization (BatchN  (None, 9, 9, 64)         256       
 ormalization)                                                   
                                                                 
 conv2d_1 (Conv2D)           (None, 9, 9, 64)          36928     
                                                                 
 batch_normalization_1 (Batc  (None, 9, 9, 64)         256       
 hNormalization)                                                 
                                                                 
 conv2d_2 (Conv2D)           (None, 9, 9, 128)         8320      
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 162)               1679778   
                                                                 
 reshape (Reshape)           (None, 81, 2)             0         
                                                                 
 activation (Activation)     (None, 81, 2)             0         
                                                                 
=================================================================
Total params: 1,726,178
Trainable params: 1,725,922
Non-trainable params: 256
_________________________________________________________________
None
evaluation:
782/782 [==============================] - 2s 2ms/step - loss: 0.0645
Loss: 0.06447835266590118
Acc whole board: 0.26
Acc single cell: 0.98